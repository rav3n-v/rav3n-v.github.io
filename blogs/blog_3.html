<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description" content="Derivation of Gradient Descent using Taylor Series Expansion">
  <meta name="date" content="February 19, 2026">
  <title>Optimization - Gradient Descent via Taylor Expansion</title>

  <link rel="stylesheet" href="blog_styles_2.css" />

  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body class="dark-theme">

<header role="banner">
  <div class="header-container">
    <h1>Optimization Theory</h1>
    <nav role="navigation">
      <a href="../index.html" class="nav-link">Home</a>
    </nav>
  </div>
  <p class="subtitle">Mathematical Foundations of Machine Learning</p>
</header>

<main role="main">

  <aside class="in-page-navigation" role="navigation">
    <h3 class="in-page-nav-heading">On this page</h3>
    <ul>
      <li><a href="#post-title">Gradient Descent via Taylor Expansion</a></li>
      <li><a href="#motivation">Motivation</a></li>
      <li><a href="#taylor">Taylor Series Expansion</a></li>
      <li><a href="#direction">Choosing a Descent Direction</a></li>
      <li><a href="#step">Deriving the Update Rule</a></li>
      <li><a href="#multivariable">Multivariable Case</a></li>
      <li><a href="#conclusion">Conclusion</a></li>
    </ul>
  </aside>

  <article role="article" aria-labelledby="post-title" class="content">

    <h2 id="post-title">Gradient Descent via Taylor Series Expansion</h2>
    <p class="meta">Posted on February 19, 2026</p>

    <h2 id="motivation">Motivation</h2>
    <p>
      Suppose we want to minimize a differentiable function
      \( f : \mathbb{R}^n \to \mathbb{R} \).
      The central question is:
    </p>

    <p><strong>How should we move from a current point to reduce the function value?</strong></p>

    <p>
      The answer comes naturally from the Taylor series expansion.
    </p>

    <h2 id="taylor">First Order Taylor Series Expansion</h2>

    <p>
      Let us first consider the one-dimensional case.
      For a differentiable function \( f(x) \),
      the Taylor expansion around a point \( x_k \) is:
    </p>

    <div class="math">
      \[
      f(x_k + h) = f(x_k) + h f'(x_k) + \mathcal{O}(h^2)
      \]
    </div>

    <p>
      If \( h \) is small, we neglect higher order terms:
    </p>

    <div class="math">
      \[
      f(x_k + h) \approx f(x_k) + h f'(x_k)
      \]
    </div>

    <p>
      This approximation tells us how the function changes locally.
    </p>

    <h2 id="direction">Choosing a Direction that Decreases the Function</h2>

    <p>
      We want:
    </p>

    <div class="math">
      \[
      f(x_k + h) < f(x_k)
      \]
    </div>

    <p>
      Using the approximation:
    </p>

    <div class="math">
      \[
      f(x_k) + h f'(x_k) < f(x_k)
      \]
    </div>

    <p>
      Cancel \( f(x_k) \):
    </p>

    <div class="math">
      \[
      h f'(x_k) < 0
      \]
    </div>

    <p>
      Therefore, to decrease the function:
    </p>

    <div class="math">
      \[
      h \text{ must have opposite sign to } f'(x_k)
      \]
    </div>

    <p>
      The simplest choice is:
    </p>

    <div class="math">
      \[
      h = -\alpha f'(x_k)
      \]
    </div>

    <p>
      where \( \alpha > 0 \) is a small scalar called the learning rate.
    </p>

    <h2 id="step">Deriving the Gradient Descent Update Rule</h2>

    <p>
      Substituting \( h \) into \( x_{k+1} = x_k + h \):
    </p>

    <div class="math">
      \[
      x_{k+1} = x_k - \alpha f'(x_k)
      \]
    </div>

    <p>
      This is the gradient descent update rule in one dimension.
    </p>

    <h2 id="multivariable">Multivariable Case</h2>

    <p>
      Now let \( f : \mathbb{R}^n \to \mathbb{R} \).
      The first order Taylor expansion becomes:
    </p>

    <div class="math">
      \[
      f(\mathbf{x}_k + \mathbf{h})
      = f(\mathbf{x}_k)
      + \nabla f(\mathbf{x}_k)^T \mathbf{h}
      + \mathcal{O}(\|\mathbf{h}\|^2)
      \]
    </div>

    <p>
      Ignoring higher order terms:
    </p>

    <div class="math">
      \[
      f(\mathbf{x}_k + \mathbf{h})
      \approx
      f(\mathbf{x}_k)
      + \nabla f(\mathbf{x}_k)^T \mathbf{h}
      \]
    </div>

    <p>
      To minimize this linear approximation,
      we choose \( \mathbf{h} \) in the direction that makes
      \( \nabla f(\mathbf{x}_k)^T \mathbf{h} \) most negative.
    </p>

    <p>
      By Cauchy–Schwarz inequality,
      the steepest descent direction is:
    </p>

    <div class="math">
      \[
      \mathbf{h} = -\alpha \nabla f(\mathbf{x}_k)
      \]
    </div>

    <p>
      Therefore, the general gradient descent update rule is:
    </p>

    <div class="math">
      \[
      \mathbf{x}_{k+1}
      =
      \mathbf{x}_k
      -
      \alpha \nabla f(\mathbf{x}_k)
      \]
    </div>

    <h2 id="conclusion">Conclusion</h2>

    <p>
      Gradient descent is not a mysterious rule.
      It follows directly from:
    </p>

    <ul>
      <li>First order Taylor approximation</li>
      <li>Linearization of the function</li>
      <li>Choosing the direction of maximal decrease</li>
    </ul>

    <p>
      The negative gradient is the direction of steepest descent
      because it minimizes the first-order local approximation of the function.
    </p>

    <p>
      Higher-order methods (Newton’s method, quasi-Newton methods)
      arise when we include second-order Taylor terms.
    </p>

  </article>

</main>

<footer role="contentinfo">
  <p>
    © 2026 Vinayak Devesan.
    Content licensed under
    <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">
      CC BY 4.0
    </a>.
  </p>
</footer>

</body>
</html>
