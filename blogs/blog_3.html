<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B32571Q9D0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-B32571Q9D0');
</script>

  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description" content="Why Gradient Descent Works - A derivation using Taylor Series expansion.">
  <meta name="date" content="February 19, 2026">
  <title>Deep Learning - Why Gradient Descent Works</title>

  <link rel="stylesheet" href="blog_styles_2.css" />
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body class="dark-theme">

<header role="banner">
  <div class="header-container">
    <h1>Deep Learning</h1>
    <nav role="navigation">
      <a href="../index.html" class="nav-link" aria-label="Back to Home">Home</a>
    </nav>
  </div>
  <p class="subtitle">Mathematics behind AI</p>
</header>

<main role="main">

  <aside class="in-page-navigation" role="navigation">
    <h3 class="in-page-nav-heading">On this page</h3>
    <ul>
      <li><a href="#post-title">Why Gradient Descent Works</a></li>
      <li><a href="#introduction">Introduction</a></li>
      <li><a href="#taylor">Taylor Series Expansion</a></li>
      <li><a href="#minimization">From Approximation to Minimization</a></li>
      <li><a href="#update">Gradient Descent Update Rule</a></li>
      <li><a href="#multivariable">Extension to Multiple Dimensions</a></li>
      <li><a href="#references">References</a></li>
    </ul>
  </aside>

  <article role="article" aria-labelledby="post-title" class="content">

    <h2 id="post-title">Why Gradient Descent Works</h2>
    <p class="meta">Posted on June 29, 2025</p>
          <div class="svg-container" style="background-color: #1e1e1e"><img viewBox="0 0 2000 800" src="Images/Blog_3_Images/3D_plot.svg"></div>


    <h2 id="introduction">Introduction</h2>

    <p>
      Gradient Descent is one of the most fundamental optimization algorithms used in machine learning.
      But why does moving in the direction of the negative derivative reduce the function value?
      The answer comes directly from the Taylor series expansion.
    </p>

    <h2 id="taylor">Taylor Series Expansion</h2>

    <p>
      Suppose \( f(x) \) is a continuously differentiable function.
      Around a point \( x \), the Taylor expansion gives:
    </p>

    <div class="math">
      \[
      f(x+h)
      =
      f(x)
      +
      h f'(x)
      +
      \frac{h^2}{2!} f''(x)
      +
      \frac{h^3}{3!} f'''(x)
      + \cdots
      \]
    </div>

    <p>
      If \( h \) is very small, higher-order terms become negligible.
      Keeping only the first-order term:
    </p>

    <div class="math">
      \[
      f(x+h) \approx f(x) + h f'(x)
      \]
    </div>

    <p>
      This is called the first-order approximation of the function.
    </p>

    <h2 id="minimization">From Approximation to Minimization</h2>

    <p>
      Suppose we want to decrease the function value.
      That means:
    </p>

    <div class="math">
      \[
      f(x+h) - f(x) < 0
      \]
    </div>

    <p>
      Using the first-order approximation:
    </p>

    <div class="math">
      \[
      f(x+h) - f(x) \approx h f'(x)
      \]
    </div>

    <p>
      Therefore, to ensure decrease:
    </p>

    <div class="math">
      \[
      h f'(x) < 0
      \]
    </div>

    <p>
      We cannot control the sign of \( f'(x) \),
      but we can control the direction of movement \( h \).
      To guarantee that the product is negative, we choose:
    </p>

    <div class="math">
      \[
      h = - \alpha f'(x) \implies h*f'(x)= -(f'*(x))^2<0
      \]
    </div>

    <p>
      Since the square of real valued inputs always give a positive value, -(f'(x))^2 it is always negative.
      Where \( \alpha > 0 \) is a small constant called the learning rate.
      This ensures that we move in the direction opposite to the slope,
      which locally decreases the function value.
    </p>

    <h2 id="update">Gradient Descent Update Rule</h2>

    <p>
      Writing this iteratively:
    </p>

    <div class="math">
      \[
      x_{k+1}
      =
      x_k
      -
      \alpha f'(x_k)
      \]
    </div>

    <p>
      This is precisely the Gradient Descent update rule.
      The algorithm repeatedly moves in the direction of steepest descent,
      gradually approaching a local minimum.
    </p>

    <h2 id="multivariable">Extension to Multiple Dimensions</h2>

    <p>
      For functions of multiple variables \( f : \mathbb{R}^n \to \mathbb{R} \),
      the derivative generalizes to the gradient:
    </p>

    <div class="math">
      \[
      \mathbf{x}_{k+1}
      =
      \mathbf{x}_k
      -
      \alpha \nabla f(\mathbf{x}_k)
      \]
    </div>

    <p>
      The gradient points in the direction of steepest increase.
      Therefore, its negative points in the direction of steepest decrease.
      This is why gradient descent works.
    </p>
    <h2 id="intuitive">Intuitive Understanding</h2>
    The slope gives us information about the rate of change of the function with respect to the variable.

If the slope at a point is positive, then the function is increasing in that direction. Therefore, to decrease the function value, we should move in the opposite direction. That is why we move in the direction of -f'(x)
Now suppose the slope at a point is negative. Then the function is decreasing in that direction. Since we want to continue decreasing the function value, we should keep moving in that same direction. However, because the slope itself is negative, multiplying it by
−1 makes the step direction positive, which ensures that we continue moving forward in the direction that reduces the function value.
Thus, moving in the direction of the negative slope always guides us toward a minimum.
    <h2 id="references">References</h2>

    <ol>
      <li>
        Charu C. Aggarwal,
        <em>Linear Algebra and Optimization for Machine Learning</em>.
        Springer Cham, 2020.
      </li>
      <li>
        Goodfellow, I., Bengio, Y., & Courville, A. (2016).
        <em>Deep Learning</em>. MIT Press.
      </li>
    </ol>

  </article>

</main>

<footer role="contentinfo">
  <p>
    © 2025 Vinayak Devesan. Content licensed under
    <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer">
      CC BY 4.0
    </a>.
  </p>
</footer>

</body>
</html>
